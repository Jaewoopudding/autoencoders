{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from src.autoencoder import Autoencoder, VariationalAutoEncoder\n",
    "from utils.mnist_loader import data_download, data_loader\n",
    "from utils.model_trainer import autoencoder_trainer, vae_trainer\n",
    "from utils.visualization import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "number of training data :  60000\n",
      "number of test data :  10000\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda:0\" if USE_CUDA else \"cpu\")\n",
    "EPOCHS = 100\n",
    "SAMPLES = 5\n",
    "print(DEVICE)\n",
    "train_data, test_data = data_download()\n",
    "train_loader, test_loader = data_loader(train_data, test_data, batch_size=256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae=Autoencoder(n_hidden=336, z_dim=128).to(DEVICE)\n",
    "criteria = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(ae.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [01:01<1:41:09, 61.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 1 - Train loss: 0.05994917452335358 - Test loss: 0.06586161255836487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [01:50<1:28:03, 53.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 2 - Train loss: 0.04470355436205864 - Test loss: 0.05165022984147072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [02:41<1:25:42, 53.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 3 - Train loss: 0.03216629475355148 - Test loss: 0.03152737393975258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [03:32<1:23:02, 51.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 4 - Train loss: 0.023872731253504753 - Test loss: 0.02698400989174843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [04:20<1:20:00, 50.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 5 - Train loss: 0.0218028724193573 - Test loss: 0.024065382778644562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [05:16<1:22:24, 52.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 6 - Train loss: 0.018279846757650375 - Test loss: 0.015342233702540398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [06:11<1:22:18, 53.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 7 - Train loss: 0.016401059925556183 - Test loss: 0.01529289036989212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [07:03<1:21:10, 52.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 8 - Train loss: 0.014605911448597908 - Test loss: 0.01206214539706707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [08:01<1:22:51, 54.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 9 - Train loss: 0.013592381961643696 - Test loss: 0.013408157974481583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [09:07<1:27:05, 58.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 10 - Train loss: 0.01216402929276228 - Test loss: 0.009272782132029533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [10:15<1:30:26, 60.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 11 - Train loss: 0.012111456133425236 - Test loss: 0.011633534915745258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [11:14<1:28:37, 60.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 12 - Train loss: 0.010128813795745373 - Test loss: 0.012046068906784058\n"
     ]
    }
   ],
   "source": [
    "train_loss, test_loss = autoencoder_trainer(model=ae, \n",
    "                                            criteria=criteria, optimizer=optimizer, \n",
    "                                            train_loader=train_loader, test_loader=test_loader, \n",
    "                                            device=DEVICE, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(loader=test_loader, model=ae, device=DEVICE, num_of_samples=SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(test_loss))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(reconstruction, x, mu, log_var):\n",
    "    reconstruction_loss = nn.functional.binary_cross_entropy(reconstruction, x, reduction='sum') # bernoulli distribution assumption\n",
    "    kl_loss = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return reconstruction_loss, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoEncoder(n_hidden=336, z_dim=128).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)\n",
    "criteria = vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_loss = vae_trainer(model=vae, beta=1,\n",
    "                                    criteria=criteria, optimizer=optimizer, \n",
    "                                    train_loader=train_loader, test_loader=test_loader, \n",
    "                                    device=DEVICE, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(loader=test_loader, model=vae, device=DEVICE, num_of_samples=SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.cpu()\n",
    "generated_samples = vae.generate(SAMPLES)\n",
    "\n",
    "for sample in generated_samples:\n",
    "    plt.matshow(sample.reshape(28,28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(test_loss))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta-Variation Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_vae = VariationalAutoEncoder(n_hidden=336, z_dim=128).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(b_vae.parameters(), lr=0.001)\n",
    "criteria = vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_loss = vae_trainer(model=b_vae, beta=4,\n",
    "                                    criteria=criteria, optimizer=optimizer, \n",
    "                                    train_loader=train_loader, test_loader=test_loader, \n",
    "                                    device=DEVICE, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(loader=test_loader, model=b_vae, device=DEVICE, num_of_samples=SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_vae.cpu()\n",
    "generated_samples = b_vae.generate(SAMPLES)\n",
    "\n",
    "for sample in generated_samples:\n",
    "    plt.matshow(sample.reshape(28,28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(test_loss))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoencoders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
